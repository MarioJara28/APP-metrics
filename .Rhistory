library(readxl)
library(lubridate)
library(tidyverse)
library(sqldf)
library(ggplot2)
#############################################Datasets sent from Talabat
example <- read_xlsx("C:/Users/mario/Desktop/Downloads/assignment_example_order_data.xlsx")
example <- as.data.frame(example)
example[,1] <- as_date(example[,1])
example[,1]<- round_date(example[,1], "months")
casedata <- read_xlsx("C:/Users/mario/Desktop/Downloads/Case study data - Cohorts.xlsx")
casedata <- as.data.frame(casedata)
casedata[,2] <- as_date(casedata[,2])
casedata[,2]<- round_date(casedata[,2], "months")
#OBJECTIVE 1-  Using the Cohort Analysis Technique, please analyse the growth of orders and clients on a monthly basis.
######Also, analyse seasonality of the orders for this dataset.
#(Seasonality is defined by an event occurring at a specific regular interval less than a year, such as weekly, monthly, or quarterly).
#Please use sql, tableau/any visualization tool and use the workbook 'case study data - cohorts'
#In order to prepare the date im going to use an R package called SQLDF; basically this package mymics
#sql syntax to manipulate and mainly group the date accordingly to the objetive.
############################################SQL queries##############################################
##Inner join of both datasets
inner <- sqldf("select example.*,casedata.*   from example
inner join
casedata
on
iso_date=Date
")
#Technique used: Cohort analysis
#Client growth monthly
growth_rate = clientgrouping %>%
# first sort by year
arrange(Date) %>%
mutate(Diff_month = month(Date) - lag(month(Date)),  # Difference in time (just in case there are gaps)
Diff_growth = clients - lag(clients), # Difference in route between years
Rate_percent = Diff_growth/lag(clients) * 100
) # growth rate in percent
Average_growth = mean(growth_rate$Rate_percent, na.rm = TRUE)
print(growth_rate)
print(Average_growth)
write.csv(growth_rate, "growth_rate_clients.csv")
write.csv(Average_growth, "average_growth_clients.csv")
#Orders growth monthly
growth_rate = ordersgrouping %>%
# first sort by year
arrange(Date) %>%
mutate(Diff_month = month(Date) - lag(month(Date)),  # Difference in time (just in case there are gaps)
Diff_growth = orders - lag(orders), # Difference in route between years
Rate_percent = Diff_growth/lag(orders) * 100
) # growth rate in percent
Average_growth = mean(growth_rate$Rate_percent, na.rm = TRUE)
print(growth_rate)
print(Average_growth)
write.csv(growth_rate, "growth_rate_orders.csv")
write.csv(Average_growth, "average_growth_orders.csv")
###################################################Cohort analysis
appname <- "Talabat"
#https://stuifbergen.com/2018/03/cohort-analysis-with-snowplow-and-r/
dbdata <- as.data.frame(cbind(casedata[,3],substr(casedata[,2], 1, 7)))
z <- list("user_id", "yw")
colnames(dbdata)<- z
colnames(dbdata)
dbdata <- sqldf("select * from dbdata group by 1,2")
cohort <- dbdata %>%           # store in cohort table, get from dbdata
group_by(user_id) %>%        # group all users together
mutate(first = min(yw)) %>%  # for every user, find the first period
group_by(first, yw) %>%      # group by this first period + the other periods
summarise(users = n()) %>%   # for each combination, count the number of users
spread(yw, users)            # and make columns with period names
#Grouping of casedata
clientgrouping <- sqldf("select  Date, count(distinct(Client)) as clients from casedata group by 1")
#Grouping of casedata
clientgrouping <- sqldf("select  Date, count(distinct(Client)) as clients from casedata group by 1")
clientmin <- sqldf("select  min(Date) as date , Client as clients from casedata group by 2")
clientmin[,1] <- as_date(clientmin[,1])
ordersgrouping <- sqldf("select  Date, count(distinct(Order_id)) as orders from casedata group by 1")
######################################################################################################
#Technique used: Cohort analysis
#Client growth monthly
growth_rate = clientgrouping %>%
# first sort by year
arrange(Date) %>%
mutate(Diff_month = month(Date) - lag(month(Date)),  # Difference in time (just in case there are gaps)
Diff_growth = clients - lag(clients), # Difference in route between years
Rate_percent = Diff_growth/lag(clients) * 100
) # growth rate in percent
Average_growth = mean(growth_rate$Rate_percent, na.rm = TRUE)
print(growth_rate)
print(Average_growth)
write.csv(growth_rate, "growth_rate_clients.csv")
write.csv(Average_growth, "average_growth_clients.csv")
#Orders growth monthly
growth_rate = ordersgrouping %>%
# first sort by year
arrange(Date) %>%
mutate(Diff_month = month(Date) - lag(month(Date)),  # Difference in time (just in case there are gaps)
Diff_growth = orders - lag(orders), # Difference in route between years
Rate_percent = Diff_growth/lag(orders) * 100
) # growth rate in percent
Average_growth = mean(growth_rate$Rate_percent, na.rm = TRUE)
print(growth_rate)
print(Average_growth)
write.csv(growth_rate, "growth_rate_orders.csv")
write.csv(Average_growth, "average_growth_orders.csv")
###################################################Cohort analysis
appname <- "Talabat"
#https://stuifbergen.com/2018/03/cohort-analysis-with-snowplow-and-r/
dbdata <- as.data.frame(cbind(casedata[,3],substr(casedata[,2], 1, 7)))
z <- list("user_id", "yw")
colnames(dbdata)<- z
colnames(dbdata)
dbdata <- sqldf("select * from dbdata group by 1,2")
cohort <- dbdata %>%           # store in cohort table, get from dbdata
group_by(user_id) %>%        # group all users together
mutate(first = min(yw)) %>%  # for every user, find the first period
group_by(first, yw) %>%      # group by this first period + the other periods
summarise(users = n()) %>%   # for each combination, count the number of users
spread(yw, users)            # and make columns with period names
########## 3: make pretty
shiftrow <- function(v) {
# put a vector in, strip off leading NA values, and place that amount at the end
first_na_index <- min( which(!is.na(v)) )
# return that bit to the end,  and pad with NAs.
c(v[first_na_index:length(v)], rep(NA, first_na_index-1))
}
# create a new dataframe, with shifted rows (and keep the first one)
shifted <- data.frame(
cohort = cohort$first,
t(apply( select(as.data.frame(cohort), 2:ncol(cohort)), # 2nd column to the end
1, # for every row
shiftrow ))
)
# and make column names readable
# first should be "cohort" and the rest month.<number>, (padded)
colnames(shifted) <- c("cohort", sub("","month.", str_pad(1:(ncol(shifted)-1),2,pad = "0")))
# percentages
shifted_pct <- data.frame(
cohort = shifted$cohort, # first column
shifted[,2:nrow(shifted)+1] / shifted[["month.01"]] # rest: divide by month.01
)
######### 4: prepare plot data
# ggplot loves long data. Let's melt it. One for the absolute values, one for the pcts
plotdata_abs <- gather(shifted,     "cohort_age", "people"  ,2:ncol(shifted    ))
plotdata_pct <- gather(shifted_pct, "cohort_age", "percent" ,2:ncol(shifted_pct))
# now add some data.. we need pretty labels..
# first bit is the length of the width of the wide column (minus 1, that's the cohort name)
# that contains the absolute numbers
# last bit is the rest, those are percentages.
labelnames <- c( plotdata_abs$people[1:(ncol(shifted)-1)],
plotdata_pct$percent[(ncol(shifted)):(nrow(plotdata_pct))])
# we need pretty labels.
pretty_print <- function(n) {
case_when( n <= 1  ~ sprintf("%1.0f %%", n*100),
n >  1  ~ as.character(n),
TRUE    ~ " ") # for NA values, skip the label
}
# create the plot data
plotdata <- data.frame(
cohort     = plotdata_pct$cohort,
cohort_age = plotdata_pct$cohort_age,
percentage = plotdata_pct$percent,
label      = pretty_print(labelnames)
)
######### 5: plot!
# plot (with reordered y axis, oldest group on top)
# optional: if the percentages are really low, replace the 1.0 in the first column with zero
plotdata[which(plotdata$percentage == 1), "percentage"] <- 0
ggplot(plotdata, aes(x = cohort_age, y = reorder(cohort, desc(cohort)))) +
geom_raster(aes(fill = percentage)) +
scale_fill_continuous(guide = FALSE) + # no legend
geom_text(aes(label = label), color = "white") +
xlab("cohort age") + ylab("cohort") +
ggtitle(paste("Retention table (cohort) for",appname, "app"))
library(forecast)
casedata <- read_xlsx("C:/Users/mario/Desktop/Downloads/Case study data - Cohorts.xlsx")
casedata <- as.data.frame(casedata)
x <- casedata %>%           # store in cohort table, get from dbdata
select(Order_id, Date)%>%
group_by(Date) %>%        # group all users together
summarise(n = n())
timeseries <- ts(x$n, start=c(2017, 10,01), end=c(2018, 10,01), frequency=365)
tim <- plot.ts(timeseries)
stl(timeseries)
decompose(timeseries)
example <- read_xlsx("C:/Users/mario/Desktop/Downloads/assignment_example_order_data.xlsx")
example <- as.data.frame(example)
y <- sqldf("select iso_date, avg(is_ramadan), avg(is_important_day), avg(is_holiday), sum(succ_orders) from example group by 1")
y[,1]<- as_date(y[,1])
timeseries <- ts(y$`sum(succ_orders)`, start=c(2017, 10,01), end=c(2018, 10,01), frequency=365)
tim <- plot.ts(timeseries)
stl(timeseries)
decompose(timeseries)
##Results of relevant variables for predicting orders
m <- summary(lm(y$`sum(succ_orders)`~ y$`avg(is_ramadan)`+ y$`avg(is_important_day)`+ y$`avg(is_holiday)`))
print(m)
View(cohort)
View(shifted)
ts(y)
stl(y)
decompose(y)
auto.arima(y)
library(forecast)
auto.arima(y)
HoltWinters(y)
